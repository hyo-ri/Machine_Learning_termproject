{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1958cc9",
   "metadata": {},
   "source": [
    "### 1. Loading all necessary libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cd12f04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Activation, MaxPool2D, Flatten, Dropout, BatchNormalization\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import visualkeras\n",
    "from keras.utils import plot_model\n",
    "import math\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23911e61",
   "metadata": {},
   "source": [
    "##### Setting the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "31641e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Img_shape = 28\n",
    "Num_classes = 10\n",
    "test_size = 0.25\n",
    "random_state = 1234\n",
    "epochs = 50\n",
    "Batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f323464a",
   "metadata": {},
   "source": [
    "### 2. Loading the Fashion MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "42fd00b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv(\"fashion-mnist_train.csv\")\n",
    "test_dataset = pd.read_csv(\"fashion-mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d752823",
   "metadata": {},
   "source": [
    "##### Reading and Labeling the 10 Clothing categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "33e393b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac5a688",
   "metadata": {},
   "source": [
    "### 3. Pre-processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4b526854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(raw):\n",
    "    label = tf.keras.utils.to_categorical(raw.label, 10)\n",
    "    num_images = raw.shape[0]\n",
    "    x_as_array = raw.values[:, 1:]\n",
    "    x_shaped_array = x_as_array.reshape(num_images, 28, 28, 1)\n",
    "    image = x_shaped_array / 255\n",
    "    return image, label\n",
    "\n",
    "X, y = data_preprocessing(train_dataset)\n",
    "X_test, y_test = data_preprocessing(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf98320",
   "metadata": {},
   "source": [
    "##### Splitting the training data into training and validation set into a split ratio of 75-25 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0d62a2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = test_size, random_state = random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7039a5",
   "metadata": {},
   "source": [
    "### 4. Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1ae6cc",
   "metadata": {},
   "source": [
    "##### Lets keep the CNN model simple initially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a04a5b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are using sequential model which is linear stack of layers.\n",
    "# The Sequential model is initialized first and then using add method we add rest of the layers\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# First layer, which has a 2D Convolutional layer with kernel size as 3x3 and Max pooling operation\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding = 'same', input_shape = (28, 28, 1)))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Second layer, which has a 2D Convolutional layer with kernel size as 3x3 & ReLU activation and Max pooling operation\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding = 'same', activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Fully connected layer with ReLU activation function\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = tf.nn.relu))\n",
    "\n",
    "# Output layer with softmax activation function\n",
    "\n",
    "model.add(Dense(10, activation = tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d76196",
   "metadata": {},
   "source": [
    "##### Model's summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a0a12135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 14, 14, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 7, 7, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               401536    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 421,642\n",
      "Trainable params: 421,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b20ae4c",
   "metadata": {},
   "source": [
    "##### 3D visualization of our CNN model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a566f7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhgAAACWCAYAAACcofGRAAAVcUlEQVR4nO3deXRU5f3H8c/MZCcQEoiIuCGIEqwLoFBASwUXtCIuLeUnLrigYl1xq9VWS90QtCp1wRaVagGpuFVAyyqrEsMmW9gEEiIQwmTPJJl5fn/QqEgCSeZm7r3D+3UO/yR37vceDod5n2fufcZjjDFyGWOMRtwyRO9P+0itUxPDPl8oZLSvsFwl5UHtyN2ltLQ0C64SAIAjV4zdF9BQxhjdf/dNWrpwlrImX6a0FvFhnS8UCumyu2Zpr79M1UFDXAAAYAGv3RfQEDVxMefzj/XJS+dbFhf5/oCe/t0Zct9aDgAAzuSawGjKuJg25lylpsSLvgAAwBquCIwmj4sWcYrxeuTC21EAAHAkxwdGJOJCknw+j1jCAADAGo4OjEjFhbQ/MAyFAQCAJRwbGJGMC0mK8Xm5yRMAAIs4MjAiHReSFOPziMIAAMAajgsMO+JCknxej8z/5gMAgPA4KjDsigtJ8no9378GAACExzGBYWdc1PB4pKqqqrDmAgAAhwSGE+JCkjzyqLq6OqzZAADAAYHhlLiQJLGCAQCAJWwNDEfFhSSPhxUMAACsYFtgOC0uJMkjVjAAALCCLYHhxLiQJLGCAQCAJSIeGI6NC/EUCQAAVoloYDg5LqT9T5EQGAAAhC9igeH0uJD2r2DwEQkAAOGLSGC4IS4kSR5WMAAAsEKTB4Zr4kL7nyJhBQMAgPA1aWC4KS4kbvIEAMAqTRYYbosLia3CAQCwSpMEhhvjQhJbhQMAYBHLA8O1cSG2CgcAwCqWBoab40Jiq3AAAKxiWWC4PS6k/SsYBAYAAOGzJDCiIS4kSWy0BQCAJcIOjKiJC7FVOAAAVgkrMKIpLiS2CgcAwCqNDoxoiwtJbBUOAIBFGhUYURkXYqtwAACs0uDAiNa4kHiKBAAAqzQoMKI5LiRWMAAAsEq9AyPa40ISW4UDAGCRegXGEREXsv4jEmOMsrOzLTuf0+cCAFDDY4wxhzrAGKNBl5yrrzKz5PV45PF4wh4aCoVkjNH8N/opLSW8WLHKuq2Fuv7er2W8PsUnJIR9PmOMTHlAOYFindihQ51/b8YYhQJ7ZeSRz+ezZG6golTNm7fUshUbFRfnjHgDABxZYg53QFVVldqf1F7HpezTiMFdLBn6/D9X6f1ZWzR64jo9dccZ8nrDj5ZwGGM0/q2tSgr59ELHXyjWG97+Y6GQ0cjs+VpVWqDrBl6hB54eVefcvz73Jy1bMlev/aGnYmPDm2tCRrc9uUQbNhep3TFJxAUAwDaHDYy4uDi1TGkphRKV0SHVkqHHtknWOaela/WmQo18YbnG3HOWfD57IsMYo8efW6uVKwo15WeXKDU2vNWLUCikIaunKxAKauhRndTu6LbKyMiode79d9+kzKXz9J+X+1n2sVOgMqgbftVe736WI7/fr5YtW4Z1XgAAGsPyr2uvr9gYr957pre25ZXqztGZqg6GIn4NNXGxYHG+Jp1mXVzsrarQxE79lOKrfQWhqe9paZ2aoOOObatZs2aFdV4AABrLtsCQpGaJMXr3yV4qKKrU8L8sU2VV5CLjgLjoYn1ctIypPRoidcNsx5OO18yZM8M6NwAAjWVrYEhSYrxPbz/RU8FgSDc+sVQVlcEmnxntcSFJHdsfpxkzZugw9/ACANAkbA8MSYqP8+nvf+yhxPgYXfvYEpVVNN1mV0dCXEhSWlpLJSUlaeXKlWHNAQCgMRwRGNL+ezJefaS7jkpN0P89slglZdZveHWkxEWNAQMGaMaMGWHNAgCgMRwTGJIU4/Pq5Qe7qcOxyfrNw4tUVGLtpldHUlxI0sUXX8x9GAAAWzgqMCTJ6/VozL1n6cxOqbrqgQUqKAqEfU4742LZ6oW27YDat29fLV++XH6/P6y5AAA0lOMCQ9q/ZfeTd5yuc7sepStGLtCefRWNPpedcfFN3F7tLsixbXv1pKQk9enTh8dVAQAR58jAkPZHxmM3d9Glfdpp0H0L9F1+eYPPYWdcjCldrn3xFZZuotWY727hYxIAgB0cGxjS/sh48PrOGnzh8Rp43xfasaus3q+1Oy6+Cu3Sf8b1t/2L4QYMGKCZM2fyuCoAIKIcHRg17hpyim4e1EGD7vtCW3eWHPZ4J8TFJ+PsXbmocfLJJysxMVGrVq0K61oAAGgIVwSGJA2/sqPuGnKKrhi5QBu3F9d5HHFxsEsuuUTTp08P63oAAGgI1wSGJF3/q/b6/bAMXXn/Aq3dUnjQ74mL2nEfBgAg0lwVGJI0+MITNGrE6fr1Qwu1aqP/+58TF3Xr27evVqxYweOqAICIcV1gSNKgvsdq9N1n6be/X6TMtQXExWEkJiaqd+/ePK4KAIiYGLsvoLEu7XOM4mO9GvqHRep+Qroy1xfosfY99VXhd2Gd1xjphe1fqyxYradP7KE9VeXaU3XwI7KBYLXertigRYV5evLOblq8YndYc2WMxkxcrfJAyNK4qHHRRRdp0qRJ6ty5syXnM8Zo2ntTNeKuO9W6dWtLzgkAiB6uDQxJ6t/jaF14Tlu9PztHJySl6G+54X+xVyAUVH6gTEfHJenRbV/VeVyhCcgfqtRJx7bQ8++srf0gI8lTv7kVlUHl7SnVjQNPUmKCr+EXfgjGGC2fNV/zP5upq/47P+zzhUJGRZXl8gcrle/fp6efflrNmjWz4EoBANHC1YEhSSOGdNLyL0u0pNe1lpxvfcleXZX5oT7rctkhj9tY7tf95Yu15sNfWzJ3zeYCXTD8U+XuKVffW2Zr7L1nqfeZ6WGf1xij+264WVnzF2p+t6st+/ioUOVql9pKfr9fXbp00YsvvqjLL7887OsFAEQHV96DEa18Pq/+8cceevzWn+mOZzN179gs+YsrG32+mriY/cEnmtTlYkvvTXmxfR/FxcRq4sSJmjBhgh566CENGjRI27ZtC2sGACA6EBgOdHGvtlrw9/6Kj/Pq3Jtm6cN5OQ3eibMp42Jip35KifnhHpHzzz9fK1euVPfu3dW9e3eNHj1aVVXWfRMuAMB9CAyHat4sVs/ceaYmPN5Dz7+zXkMfXaKcem6VbozR0s+WNFlc1PZUTXx8vB599FEtXbpU8+bNU9euXbVgwYKw5gKA0+3cuVPFxXVv/ngkz3X9PRjR7uyMVpr16vl6eUq2+t8+RyOvPVU3Duwgn6/2u0eNMfr6q0Ltya3S5NMGROyR3RodOnTQp59+qqlTp+ri64fIJ49iYvhnBiD6BKurVbRrj9qmpCk1NbXO4yqrqvRdSUCxMT55PPW88/8wcwvzd6ttq9SIzy3y79MrL4zRbcOHH/Z4/ud3gbhYr0YOPVUDz2unkS8s17TZORp731nKOCnlgONq9gPZk1upyadFbj+Q2kxbNFflcV6ZPw6VYvlnBiDKbMqVxkyVygOaNH2S0tNrvyn/u127dMU116n81F4KZJwT9tjQru0KznhbqqzQpEk2zC0v0eWXHfohiBr8z+8iJx/fXB+OPVfvzvhWVz+wUEMvPVH3DT1VCXG+AzYbszMujDEacs8ITf18uswrd0kpPL4KIMqs3y6N/bd09bnyTVukTp06qW3btgcdlpObqz4XXaLSjD6KOXdQ2GODeVsVnDFR6tZfvhVzbJtbX9yD4TJer0fXXtpec8f30+acEvW9ZbYWLt9ty06mP/XjuAj97U7iAkD0Wb9duvsV6ao+0tDz6zwsJzdXp/fsraJTfm7Zm3z1O89K3fpJPS913NzasILhUm1aJegff+yhGYt26oEnVqs4UCWvx6MLlk/70VE//cytfjt/GRNScXWVrkk/WWvL9umMZq3UzBd7mNcQFwCiHHHRIASGy/U752gtPKdAoewE3XT86Zac841tK7Xc/508HumlvFVaV7ZPHRNS1C05Xd2T09U1+cDP/IgLAFGPuGgwAsPl4mK9SkmOkzcuUacmt7LknOnxSUqPS9T97c6StH/79NVle5VZvEdT927WI9u+VLIvViVeo9dff11TZs3Q3DlzpLuvkJZvsuQaAMAxdu2TXv9EurC71DtD2vrDd16Z6qA2bNiggoICrd+wQTeO+J2KWx4jX3o7BdcvC2ts0F8gM+89qUsvqeOZUn7uD3ODTTc3VORXaN5UqfsFjY4LicBAPcR7feqefJS6Jx8lqYtCxmi2f4ee2LNK4157Vd+sWSPPsenSW/+1+1IBwHIm3y8FQ9LX2fv//EiouEy33XabvF6vNu8rVVVpuTyhXQrNnhL+3OJ9UigobVu7/8+P55aXNN3cEr887TrKhBEXEoGBRvB6PDoxoYVSk5I1+Z13deYVF8v70V/sviwAaBLVT72r0F6/9PvBB/3Od+UozZ07V23bttXA627WrEKvEvrU7zHOwyn7aLwqi/wyA248eO5rI5t8brh4igQAAFiOwAAAAJYjMAAAgOUIDAAAYDkCAwAAWI7AAAAAliMwAACA5QgMAABgOQIDAABYjsAAAACWIzAAAIDl+C4SAAAaI79QwcIS9e3bVzExMcoprZTO+GXTzy3xK1habMvcUEWZvN76rU2wggEAQEPlF8p7z+u65rZb9MEHH2jq1Knq2rVr088t8cs75Tldc5M9c4fdNkJt2rSp10tYwUCjlVYGNHr0aAWrg5QqgCNHfqF894zXiBtv0Ut/+uGbpJsnN5cKm3BuiV++957TiOE36aWnRtk+93B4X0CDGWP0771bFPJIzZs3l9fns/uSACAyvo+Lmw+IiyZX8yZ/S8Pe5O2cS2CgQYwxGp27XJlxFVq1cYNuv/12eTx2XxUARABx0SAEBuqtJi6+iqvQ3BWZSktLs/uSACAyygP2xEVlhT1xYcFc7sFAvdQVF8FgUKHygLQp1+YrBICmYQqKpVVbNfi3Q3Tr1UO0Zs2aWo/bW1AgU+ZT8LvtlswNlRbJ5GRr8JAhuvWa30ZsrikrlvK2aMQdI8KKGgIDh1VbXFRVVWny5MkaNWqU4oxHife/IY+HBTEA0ae4uEix1dLK+Ys0eP6iOo/Lr6hWTGmp4rYut2RuRVGxkrzSyiULNXjJwojNDZSU6ry+fcNeMSEwcEg/jYuEhASNGzdOY8eOVfv27TVu3DhdcMEF8nAjBoAolZ2drU6dOjG3gQgM1OnHcfHBvFl65ZVXNG7cOPXq1UuTJk1Sz5497b5EAGhydrzJR8NcAgN1Gp27XIt8Jep3+eU6++yzNXDgQM2ZM0cZGRl2XxoAwOEIDNQqu8yvTN8+mbgY+Xw+ZWVl6YQTTrD7sgAALkFg1MrYM9U0bu76bUVavH2TPtydLcmjUGj/eXyN3ABrV3mJioOVunfkSD3wwANKT09v1HkAAEcuAqNW9tyw6GnE3JmL85SZs1tvjj5bqS3i9Mp7G7VsQ0AT//WBUlJSGnUdsz77XP0uvEBdunRp1OsBACAwnKSBfbElp0T3jc3SxFE/V7fOqXpi/Ddal+PVl1+vDWsTLO6xAACEi40LXKq0vFrDHl+qB2/o/H1cLFpTpdlffM0OmwAA2xEYLmSM0b1js3TmKam67tITiQsAgOPwEYkLvf7+Jm3JLdHHL5ynP7+xhrgAADgOgeEyi1fu0ctTsjX9pV9o9NvriAsAgCPxEYmL5OWX69Ynl2ncg9305sdbiQsAgGMRGI1kjJGJ4H4ZlVUh3fTEl7rx8pM0P2sPcQEAcDQCoxGMMZqwe31Et+N67NVVap0aL39xJXEBAHA8AqOBar4AbHVsoNE7ZTbUlM+36Yus3WqXnqjFa6uJCwCA4xEYDfDjbxd98/33IjJz9Ua/Hn99tc7OSFPmxhBxAQBwBQKjnn4cF3NXZDZ6G+6GKCgK6IbHl6pb5zSty/ESFwAA1yAw6uGncRGJN/lg0Oj2pzKVlhKnXUUJxAUAwFUIjMOwIy4kafTEtdqwrUjGl0JcAABch8A4BLviYsainRo/bbNaprbWnAVZxAUAwHUIjDrYFRebdxTr1ieXqW2bdH2xeAVxAQBwJQKjDnbERShodOnd89UqraWWZn5DXAAAXMv130VijFF5sFrrS/Zacr4tZX5Vmmp94SnSm5PfU15envLy8g46buPGjSqrqNKazQWWzN24rVAFRQElJSVqxeoNxAUAwNVcHxhLV+9VtSekG9b/Rx5P489TVhFUddAouXkLVRkjb8vmGj58eJ3HBwIBGePTbx5aIo83jMH/U11VrRbJ8cpatV6tWrUK+3wAANjJ1YERDBpN+GiLxvzhdPXvcXSjzmGM0RPjv/l+++1QKCSv1xvxFYT8/Hxb5gIA0BRcHRjT5u5Qi+RY9TunTaNe/9O4sPPNvXXr1rbNBgDAaq69ybOqOqTnJq7TI8My5GnEZyNOigsAAKKNawNj8mfbdHybZup9ZnqDX0tcAADQtFwZGBWVQT3/zno9PCyjwa8lLgAAaHquDIx/frpVXTqkqHtGw+KAuAAAIDJcFxil5dV6cVK2Hr6hYasXxAUAAJHjusCY8NEW9TytlU7r2LLeryEuAACILFc9plpUUqVXp27URy+cV+/XEBcAAESeq1YwXnt/k/r1aKOTj29er+OJCwAA7OGaFYyCooAmfLRZM8f9sl7HExcAANjHNSsY46Zs1GXntdOJxzQ77LHEBQAA9nLFCsauvRV6d/q3mju+32GPJS4AALCfK1Yw/vqvDRp84fE6Jj3xkMcRFwAAOIPjVzB27CrTtDk7tHBC/0MeR1wAAOAcjl/BeP6d9br+svZKT02o8xjiAgAAZ3H0CsaWnBLNWLRTS9++sM5jiAsAAJzH0SsYz01cp+FXdlTL5nG1/p64AADAmRwbGOu2Fmp+1m4Nv7JDrb8nLgAAcC7HBsazb6/T7wZ3UnJS7EG/Iy4AAHA2RwbGig37lLWuQMMGnnTQ74gLAACcz5GB8cxba3XvNacqMd53wM+JCwAA3MFxgfHl6nxt2lGsawaceMDPiQsAANzDUYFhjNFTb67V/dd2Vlys94CfExcAALiHowJjftZu7dkX0NX9j/v+Z8QFAADu45jAMMbomTfX6sHrOyvG5/3+Z8QFAADu45jA+GzJd6qoDGngee0kERcAALiZIwIjFDJ65q21eviGDHm9HuICAACXc0RgfPxFrhLivLro50cTFwAARAHbA6M6GNKzb63Vw8MyJIm4AAAgCtgeGP+etUNt0hJ03lnpxAUAAFHC1sCorAppzD/X6eFhGfrzG2uICwAAooStgfHujG/V8bjmmrk4j7gAACCK2BYYwaDRX/+1QWkt4ogLAACijG2BsS2vRAlxXm3M8xEXAABEGVsCI1AZVPb2IsUmpBAXAABEoZj6HFRcUqqJk9do6n+/tWTozt3FSktJ1OKvVhMXAABEof8HMXICdWgs7SUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=536x150>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualkeras.layered_view(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1f1ea3",
   "metadata": {},
   "source": [
    "##### A more elaborate and labelled way of visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "372702a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model, to_file = 'model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff879217",
   "metadata": {},
   "source": [
    "##### Setting the parameters and compiling our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8f5aa299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer specified here is adam, loss is categorical crossentrophy and metric is accuracy\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = tf.keras.losses.categorical_crossentropy, metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b651a2cb",
   "metadata": {},
   "source": [
    "##### Fit and Run the model with training and validation set of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "db0ce475",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "352/352 [==============================] - 50s 137ms/step - loss: 0.4942 - accuracy: 0.8254 - val_loss: 0.3445 - val_accuracy: 0.8785\n",
      "Epoch 2/50\n",
      "352/352 [==============================] - 47s 133ms/step - loss: 0.3216 - accuracy: 0.8849 - val_loss: 0.3607 - val_accuracy: 0.8641\n",
      "Epoch 3/50\n",
      "352/352 [==============================] - 51s 145ms/step - loss: 0.2781 - accuracy: 0.9010 - val_loss: 0.2954 - val_accuracy: 0.8933\n",
      "Epoch 4/50\n",
      "352/352 [==============================] - 47s 134ms/step - loss: 0.2496 - accuracy: 0.9100 - val_loss: 0.2679 - val_accuracy: 0.9048\n",
      "Epoch 5/50\n",
      "352/352 [==============================] - 45s 127ms/step - loss: 0.2273 - accuracy: 0.9182 - val_loss: 0.2582 - val_accuracy: 0.9081\n",
      "Epoch 6/50\n",
      "352/352 [==============================] - 51s 145ms/step - loss: 0.2036 - accuracy: 0.9254 - val_loss: 0.2474 - val_accuracy: 0.9129\n",
      "Epoch 7/50\n",
      "352/352 [==============================] - 50s 142ms/step - loss: 0.1871 - accuracy: 0.9322 - val_loss: 0.2630 - val_accuracy: 0.9063\n",
      "Epoch 8/50\n",
      "352/352 [==============================] - 43s 123ms/step - loss: 0.1709 - accuracy: 0.9385 - val_loss: 0.2552 - val_accuracy: 0.9115\n",
      "Epoch 9/50\n",
      "352/352 [==============================] - 47s 135ms/step - loss: 0.1528 - accuracy: 0.9438 - val_loss: 0.2538 - val_accuracy: 0.9132\n",
      "Epoch 10/50\n",
      "352/352 [==============================] - 44s 126ms/step - loss: 0.1425 - accuracy: 0.9479 - val_loss: 0.2886 - val_accuracy: 0.9040\n",
      "Epoch 11/50\n",
      "352/352 [==============================] - 45s 129ms/step - loss: 0.1247 - accuracy: 0.9546 - val_loss: 0.2668 - val_accuracy: 0.9153\n",
      "Epoch 12/50\n",
      "352/352 [==============================] - 44s 126ms/step - loss: 0.1117 - accuracy: 0.9594 - val_loss: 0.2714 - val_accuracy: 0.9085\n",
      "Epoch 13/50\n",
      "352/352 [==============================] - 44s 126ms/step - loss: 0.1010 - accuracy: 0.9637 - val_loss: 0.2708 - val_accuracy: 0.9175\n",
      "Epoch 14/50\n",
      "352/352 [==============================] - 44s 125ms/step - loss: 0.0871 - accuracy: 0.9682 - val_loss: 0.2879 - val_accuracy: 0.9123\n",
      "Epoch 15/50\n",
      "352/352 [==============================] - 45s 126ms/step - loss: 0.0809 - accuracy: 0.9709 - val_loss: 0.3037 - val_accuracy: 0.9135\n",
      "Epoch 16/50\n",
      "352/352 [==============================] - 45s 127ms/step - loss: 0.0700 - accuracy: 0.9748 - val_loss: 0.3003 - val_accuracy: 0.9164\n",
      "Epoch 17/50\n",
      "352/352 [==============================] - 45s 127ms/step - loss: 0.0586 - accuracy: 0.9797 - val_loss: 0.3084 - val_accuracy: 0.9171\n",
      "Epoch 18/50\n",
      "352/352 [==============================] - 45s 129ms/step - loss: 0.0533 - accuracy: 0.9816 - val_loss: 0.3439 - val_accuracy: 0.9149\n",
      "Epoch 19/50\n",
      "352/352 [==============================] - 44s 126ms/step - loss: 0.0457 - accuracy: 0.9837 - val_loss: 0.3528 - val_accuracy: 0.9114\n",
      "Epoch 20/50\n",
      "352/352 [==============================] - 56s 159ms/step - loss: 0.0355 - accuracy: 0.9882 - val_loss: 0.3902 - val_accuracy: 0.9119\n",
      "Epoch 21/50\n",
      "352/352 [==============================] - 56s 159ms/step - loss: 0.0399 - accuracy: 0.9869 - val_loss: 0.3918 - val_accuracy: 0.9093\n",
      "Epoch 22/50\n",
      "352/352 [==============================] - 54s 154ms/step - loss: 0.0323 - accuracy: 0.9894 - val_loss: 0.3940 - val_accuracy: 0.9169\n",
      "Epoch 23/50\n",
      "352/352 [==============================] - 65s 183ms/step - loss: 0.0250 - accuracy: 0.9918 - val_loss: 0.4342 - val_accuracy: 0.9124\n",
      "Epoch 24/50\n",
      "352/352 [==============================] - 49s 140ms/step - loss: 0.0249 - accuracy: 0.9913 - val_loss: 0.4249 - val_accuracy: 0.9109\n",
      "Epoch 25/50\n",
      "352/352 [==============================] - 45s 128ms/step - loss: 0.0208 - accuracy: 0.9931 - val_loss: 0.4347 - val_accuracy: 0.9145\n",
      "Epoch 26/50\n",
      "352/352 [==============================] - 45s 127ms/step - loss: 0.0224 - accuracy: 0.9927 - val_loss: 0.4725 - val_accuracy: 0.9098\n",
      "Epoch 27/50\n",
      "352/352 [==============================] - 45s 127ms/step - loss: 0.0239 - accuracy: 0.9918 - val_loss: 0.4878 - val_accuracy: 0.9106\n",
      "Epoch 28/50\n",
      "352/352 [==============================] - 47s 133ms/step - loss: 0.0247 - accuracy: 0.9918 - val_loss: 0.4789 - val_accuracy: 0.9107\n",
      "Epoch 29/50\n",
      "352/352 [==============================] - 48s 137ms/step - loss: 0.0164 - accuracy: 0.9946 - val_loss: 0.4830 - val_accuracy: 0.9157\n",
      "Epoch 30/50\n",
      "352/352 [==============================] - 62s 177ms/step - loss: 0.0192 - accuracy: 0.9932 - val_loss: 0.5126 - val_accuracy: 0.9158\n",
      "Epoch 31/50\n",
      "352/352 [==============================] - 59s 169ms/step - loss: 0.0150 - accuracy: 0.9953 - val_loss: 0.5055 - val_accuracy: 0.9159\n",
      "Epoch 32/50\n",
      "352/352 [==============================] - 46s 132ms/step - loss: 0.0216 - accuracy: 0.9926 - val_loss: 0.5888 - val_accuracy: 0.9128\n",
      "Epoch 33/50\n",
      "352/352 [==============================] - 50s 142ms/step - loss: 0.0107 - accuracy: 0.9965 - val_loss: 0.5460 - val_accuracy: 0.9128\n",
      "Epoch 34/50\n",
      "352/352 [==============================] - 47s 135ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 0.5580 - val_accuracy: 0.9193\n",
      "Epoch 35/50\n",
      "352/352 [==============================] - 51s 146ms/step - loss: 0.0198 - accuracy: 0.9930 - val_loss: 0.5170 - val_accuracy: 0.9131\n",
      "Epoch 36/50\n",
      "352/352 [==============================] - 52s 149ms/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 0.5362 - val_accuracy: 0.9144\n",
      "Epoch 37/50\n",
      "352/352 [==============================] - 46s 130ms/step - loss: 0.0114 - accuracy: 0.9961 - val_loss: 0.6012 - val_accuracy: 0.9157\n",
      "Epoch 38/50\n",
      "352/352 [==============================] - 46s 131ms/step - loss: 0.0150 - accuracy: 0.9946 - val_loss: 0.5601 - val_accuracy: 0.9174\n",
      "Epoch 39/50\n",
      "352/352 [==============================] - 45s 129ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.5784 - val_accuracy: 0.9167\n",
      "Epoch 40/50\n",
      "352/352 [==============================] - 46s 132ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.6042 - val_accuracy: 0.9193\n",
      "Epoch 41/50\n",
      "352/352 [==============================] - 46s 132ms/step - loss: 0.0100 - accuracy: 0.9971 - val_loss: 0.6208 - val_accuracy: 0.9144\n",
      "Epoch 42/50\n",
      "352/352 [==============================] - 46s 130ms/step - loss: 0.0180 - accuracy: 0.9942 - val_loss: 0.5924 - val_accuracy: 0.9116\n",
      "Epoch 43/50\n",
      "352/352 [==============================] - 46s 131ms/step - loss: 0.0186 - accuracy: 0.9936 - val_loss: 0.6009 - val_accuracy: 0.9177\n",
      "Epoch 44/50\n",
      "352/352 [==============================] - 46s 129ms/step - loss: 0.0055 - accuracy: 0.9985 - val_loss: 0.6310 - val_accuracy: 0.9121\n",
      "Epoch 45/50\n",
      "352/352 [==============================] - 45s 129ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.5951 - val_accuracy: 0.9161\n",
      "Epoch 46/50\n",
      "352/352 [==============================] - 45s 127ms/step - loss: 0.0205 - accuracy: 0.9926 - val_loss: 0.6115 - val_accuracy: 0.9101\n",
      "Epoch 47/50\n",
      "352/352 [==============================] - 45s 129ms/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 0.6331 - val_accuracy: 0.9135\n",
      "Epoch 48/50\n",
      "352/352 [==============================] - 46s 130ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.6398 - val_accuracy: 0.9185\n",
      "Epoch 49/50\n",
      "352/352 [==============================] - 45s 129ms/step - loss: 0.0071 - accuracy: 0.9975 - val_loss: 0.6286 - val_accuracy: 0.9163\n",
      "Epoch 50/50\n",
      "352/352 [==============================] - 47s 132ms/step - loss: 0.0216 - accuracy: 0.9922 - val_loss: 0.7198 - val_accuracy: 0.9068\n"
     ]
    }
   ],
   "source": [
    "train_model = model.fit(X_train, y_train, batch_size = Batch_size, epochs = epochs, verbose = 1, validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfcdddb",
   "metadata": {},
   "source": [
    "### 5. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1e3aa3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 12ms/step - loss: 0.6742 - accuracy: 0.9138\n",
      "Test loss :  0.6742339134216309\n",
      "Test accuracy :  0.9138000011444092\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, steps = math.ceil(10000/32))\n",
    "\n",
    "# checking the test loss and test accuracy\n",
    "\n",
    "print('Test loss : ', score[0])\n",
    "print('Test accuracy : ', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578fe47a",
   "metadata": {},
   "source": [
    "### 6. Tuning the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f0a96b",
   "metadata": {},
   "source": [
    "##### Lets add Batch Normalization and Dropout layers ( To avoid overfitting ) to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "61fdcaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, 3, padding = 'same', activation = 'relu', kernel_initializer = 'he_normal', input_shape = (28, 28, 1)))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, 3, padding = 'same', activation = 'relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, 3, padding = 'same', activation = 'relu'))\n",
    "model.add(Conv2D(128, 3, padding = 'same', activation = 'relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b510f343",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "The layer has never been called and thus has no defined output shape.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [70]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mvisualkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayered_view\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\visualkeras\\layered.py:85\u001b[0m, in \u001b[0;36mlayered_view\u001b[1;34m(model, to_file, min_z, min_xy, max_z, max_xy, scale_z, scale_xy, type_ignore, index_ignore, color_map, one_dim_orientation, background_fill, draw_volume, padding, spacing, draw_funnel, shade_step, legend, font, font_color)\u001b[0m\n\u001b[0;32m     82\u001b[0m y \u001b[38;5;241m=\u001b[39m min_xy\n\u001b[0;32m     83\u001b[0m z \u001b[38;5;241m=\u001b[39m min_z\n\u001b[1;32m---> 85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_shape\u001b[49m, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m     86\u001b[0m     shape \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39moutput_shape\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer\u001b[38;5;241m.\u001b[39moutput_shape, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\n\u001b[0;32m     88\u001b[0m         layer\u001b[38;5;241m.\u001b[39moutput_shape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:  \u001b[38;5;66;03m# drop dimension for non seq. models\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:2167\u001b[0m, in \u001b[0;36mLayer.output_shape\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2153\u001b[0m \u001b[38;5;124;03m\"\"\"Retrieves the output shape(s) of a layer.\u001b[39;00m\n\u001b[0;32m   2154\u001b[0m \n\u001b[0;32m   2155\u001b[0m \u001b[38;5;124;03mOnly applicable if the layer has one output,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2164\u001b[0m \u001b[38;5;124;03m    RuntimeError: if called in Eager mode.\u001b[39;00m\n\u001b[0;32m   2165\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes:\n\u001b[1;32m-> 2167\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe layer has never been called \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2168\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mand thus has no defined output shape.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   2169\u001b[0m all_output_shapes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\n\u001b[0;32m   2170\u001b[0m     [\u001b[38;5;28mstr\u001b[39m(node\u001b[38;5;241m.\u001b[39moutput_shapes) \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes])\n\u001b[0;32m   2171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(all_output_shapes) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: The layer has never been called and thus has no defined output shape."
     ]
    }
   ],
   "source": [
    "visualkeras.layered_view(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a1758526",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [71]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplot_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\vis_utils.py:417\u001b[0m, in \u001b[0;36mplot_model\u001b[1;34m(model, to_file, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, dpi, layer_range, show_layer_activations)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;124;03m\"\"\"Converts a Keras model to dot format and save to a file.\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \n\u001b[0;32m    370\u001b[0m \u001b[38;5;124;03mExample:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;124;03m  This enables in-line display of the model plots in notebooks.\u001b[39;00m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[1;32m--> 417\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis model has not yet been built. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    418\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBuild the model first by calling `build()` or by calling \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    419\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe model on a batch of data.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    421\u001b[0m dot \u001b[38;5;241m=\u001b[39m model_to_dot(\n\u001b[0;32m    422\u001b[0m     model,\n\u001b[0;32m    423\u001b[0m     show_shapes\u001b[38;5;241m=\u001b[39mshow_shapes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    429\u001b[0m     layer_range\u001b[38;5;241m=\u001b[39mlayer_range,\n\u001b[0;32m    430\u001b[0m     show_layer_activations\u001b[38;5;241m=\u001b[39mshow_layer_activations)\n\u001b[0;32m    431\u001b[0m to_file \u001b[38;5;241m=\u001b[39m io_utils\u001b[38;5;241m.\u001b[39mpath_to_string(to_file)\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
     ]
    }
   ],
   "source": [
    "plot_model(model, to_file = 'model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bf2537",
   "metadata": {},
   "source": [
    "##### Tweaking the learning rate in adam optimizer for better accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4e36b516",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret optimizer identifier: <keras.optimizers.optimizer_v2.adam.Adam object at 0x0000022A1EB54FD0>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [74]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Adam(learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.001\u001b[39m, beta_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.9\u001b[39m, beta_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.999\u001b[39m, epsilon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, decay \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m, amsgrad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlosses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategorical_crossentropy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:570\u001b[0m, in \u001b[0;36mModel.compile\u001b[1;34m(self, optimizer, loss, metrics, loss_weights, weighted_metrics, run_eagerly, steps_per_execution, **kwargs)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_compile(optimizer, metrics, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_eagerly \u001b[38;5;241m=\u001b[39m run_eagerly\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_optimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompiled_loss \u001b[38;5;241m=\u001b[39m compile_utils\u001b[38;5;241m.\u001b[39mLossesContainer(\n\u001b[0;32m    572\u001b[0m     loss, loss_weights, output_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_names)\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompiled_metrics \u001b[38;5;241m=\u001b[39m compile_utils\u001b[38;5;241m.\u001b[39mMetricsContainer(\n\u001b[0;32m    574\u001b[0m     metrics, weighted_metrics, output_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_names,\n\u001b[0;32m    575\u001b[0m     from_serialized\u001b[38;5;241m=\u001b[39mfrom_serialized)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:608\u001b[0m, in \u001b[0;36mModel._get_optimizer\u001b[1;34m(self, optimizer)\u001b[0m\n\u001b[0;32m    605\u001b[0m       opt \u001b[38;5;241m=\u001b[39m lso\u001b[38;5;241m.\u001b[39mLossScaleOptimizerV1(opt, loss_scale)\n\u001b[0;32m    606\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m opt\n\u001b[1;32m--> 608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_get_single_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:916\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    912\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    913\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    915\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 916\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    917\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:916\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    912\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    913\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    915\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 916\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    917\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:599\u001b[0m, in \u001b[0;36mModel._get_optimizer.<locals>._get_single_optimizer\u001b[1;34m(opt)\u001b[0m\n\u001b[0;32m    598\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_single_optimizer\u001b[39m(opt):\n\u001b[1;32m--> 599\u001b[0m   opt \u001b[38;5;241m=\u001b[39m \u001b[43moptimizers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    600\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (loss_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    601\u001b[0m       \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(opt, lso\u001b[38;5;241m.\u001b[39mLossScaleOptimizer)):\n\u001b[0;32m    602\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m loss_scale \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\keras\\optimizers.py:131\u001b[0m, in \u001b[0;36mget\u001b[1;34m(identifier)\u001b[0m\n\u001b[0;32m    129\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m deserialize(config)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 131\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    132\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCould not interpret optimizer identifier: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(identifier))\n",
      "\u001b[1;31mValueError\u001b[0m: Could not interpret optimizer identifier: <keras.optimizers.optimizer_v2.adam.Adam object at 0x0000022A1EB54FD0>"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(learning_rate = 0.001, beta_1 = 0.9, beta_2 = 0.999, epsilon = None, decay = 0.0, amsgrad = False)\n",
    "\n",
    "model.compile(optimizer = optimizer, loss = keras.losses.categorical_crossentropy, metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "56e214fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [75]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mBatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1111\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1109\u001b[0m \u001b[38;5;66;03m# Legacy graph support is contained in `training_v1.Model`.\u001b[39;00m\n\u001b[0;32m   1110\u001b[0m version_utils\u001b[38;5;241m.\u001b[39mdisallow_legacy_graph(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1111\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_assert_compile_was_called\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_call_args(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1113\u001b[0m _disallow_inside_tf_function(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2725\u001b[0m, in \u001b[0;36mModel._assert_compile_was_called\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_assert_compile_was_called\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   2720\u001b[0m   \u001b[38;5;66;03m# Checks whether `compile` has been called. If it has been called,\u001b[39;00m\n\u001b[0;32m   2721\u001b[0m   \u001b[38;5;66;03m# then the optimizer is set. This is different from whether the\u001b[39;00m\n\u001b[0;32m   2722\u001b[0m   \u001b[38;5;66;03m# model is compiled\u001b[39;00m\n\u001b[0;32m   2723\u001b[0m   \u001b[38;5;66;03m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[39;00m\n\u001b[0;32m   2724\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_compiled:\n\u001b[1;32m-> 2725\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYou must compile your model before \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2726\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining/testing. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2727\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUse `model.compile(optimizer, loss)`.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "train_model = model.fit(X_train, y_train, batch_size = Batch_size, epochs = epochs, verbose = 1, validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcda2d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, steps = math.ceil(10000/32))\n",
    "\n",
    "print('Test loss : ', score[0])\n",
    "print('Test accuracy : ', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a1720e",
   "metadata": {},
   "source": [
    "### 7. Visualizing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fee7d71",
   "metadata": {},
   "source": [
    "##### Plotting 16 random images with predicted and real class of clothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef176ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {0 : \"T-shirt/top\", 1 : \"Trouser\", 2 : \"Pullover\", 3 : \"Dress\", 4 : \"Coat\", 5 : \"Sandal\", 6 : \"Shirt\", 7 : \"Sneaker\", 8 : \"Bag\", 9 : \"Ankle Boot\"}\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "X_test__ = X_test.reshape(X_test.shape[0], 28, 28)\n",
    "\n",
    "fig, axis = plt.subplots(4, 4, figsize = (12, 14))\n",
    "\n",
    "for i, ax in enumerate(axis.flat):\n",
    "    ax.imshow(X_test__[i], cmap = 'binary')\n",
    "    ax.set(title = f\"Real Class is {labels[y_test[i].argmax()]}\\nPredict Class is {labels[y_pred[i].argmax()]}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6e5835",
   "metadata": {},
   "source": [
    "##### Plotting the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62db053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis = 1)\n",
    "y_true = np.argmax(y_test, axis = 1)\n",
    "confusion_mtx = confusion_matrix(y_true, y_pred_classes)\n",
    "\n",
    "f, ax = plt.subplots(figsize = (12, 12))\n",
    "sns.heatmap(confusion_mtx, annot = True, linewidths = 0.1, cmap = \"gist_yarg_r\", linecolor = \"white\", fmt = '.0f', ax = ax)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c53cec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf1fe58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dfee24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035406c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403bcc2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
